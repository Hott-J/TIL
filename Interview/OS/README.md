# OS

## Table of Contents
* [운영체제](#운영체제)
* [프로세스 생성과정](#프로세스-생성과정)
* [프로세스와 스레드의 차이](#프로세스와-스레드의-차이)
* [멀티 프로세싱과 멀티 스레딩](#멀티-프로세싱과-멀티-스레딩)
* [Thread Safe와 Thread](#thread-safe와-thread)
* [병렬성과 동시성의 차이](#병렬성과-동시성의-차이)
* [문맥 교환(Context Switching)](#문맥-교환context-switching)
* [인터럽트](#인터럽트)
* [프로세스 동기화](#프로세스-동기화)
  * [Critical Section(공유 자원, 임계 영역)](#critical-section공유-자원-임계-영역)
  * [Race Condition](#race-condition)
  * [뮤텍스와 세마포어의 차이](#뮤텍스와-세마포어의-차이)
* [교착 상태 (Deadlock)](#교착-상태-deadlock)
* [기아 상태 (Starvation)](#기아-상태-starvation)
* [동기식과 비동기식의 차이](#동기식과-비동기식의-차이)
* [블락킹과 논블락킹의 차이](#블락킹과-논블락킹의-차이)
* [블락킹/논블락킹과 동기/비동기의 차이](#블락킹논블락킹과-동기비동기의-차이)
* [CPU 스케줄링 기법](#cpu-스케줄링-기법)
* [메모리 구성](#메모리-구성)
  * [힙과 스택의 차이](#힙과-스택의-차이)
  * [스택 영역의 장점과 단점](#스택-영역의-장점과-단점)
  * [힙 영역의 장점과 단점](#힙-영역의-장점과-단점)
* [가상 메모리와 가상 메모리 사용 시의 장점](#가상-메모리와-가상-메모리-사용-시의-장점)
* [세그멘테이션](#세그멘테이션)
* [페이징](#페이징)
* [[참고] 페이지 테이블, TLB](#참고-페이지-테이블-tlb)
* [페이지 교체 알고리즘](#페이지-교체-알고리즘)
* [캐시의 지역성](#캐시의-지역성)
* [컴퓨터가 부팅되는 과정](#컴퓨터가-부팅되는-과정)
* [심볼릭 링크와 하드 링크의 차이](#심볼릭-링크와-하드-링크의-차이)
* [컴파일러와 인터프리터의 차이](#컴파일러와-인터프리터의-차이)
* [CPU와 GPU의 차이](#cpu와-gpu의-차이)

<br>

## 운영체제
* 하드웨어를 관리하고, `응용 프로그램과 하드웨어 사이에서 인터페이스 역할`을 하는 시스템 소프트웨어

## 프로세스 생성과정
* 프로세스 관리 정보를 갖는 `Process Control Block를 생성`하고 프로그램의 코드를 읽어 들여 `코드 영역`을 메모리에 할당
* 초기화된 전역 변수 및 static 변수인 `데이터 영역`을 메모리에 할당
* `힙과 스택의 초기 메모리 주소를 초기화`
* `Queue에서 프로세스가 등록`되고 운영체제가 CPU를 할당하기를 대기

<br>

## 프로세스와 스레드의 차이
### 👉 프로세스
* `실행중인 프로그램`
* 운영체제로부터 자원을 할당받아 실행
* `코드/데이터/스택/힙` 메모리 영역

#### PCB (Process Control Block)
* 프로세스를 관리하기 위해 정보를 저장하는 커널의 자료구조(Data 영역에 존재)
* Process 상태, PC(다음에 수행할 명령어의 주소), CPU 레지스터, CPU 스케줄링 정보, 메모리 관리 정보 등을 저장
* `문맥 교환` 시에 진행 사항을 PCB에 저장하고 CPU 반환 -> CPU를 할당받으면 PCB에 저장되어 있는 내용을 불러와 이전에 종료되었던 시점부터 다시 수행

### 👉 스레드
* `프로세스의 독립적인 실행 단위`, (경량 프로세스) 
* 프로세스 안에서 프로세스로부터 자원을 받아 실행
* 프로세스의 코드/데이터/힙 메모리 영역을 공유하고 `개별적인 스택`을 가짐

#### 스레드가 개별적인 스택을 가지는 이유
* 스택에는 함수 호출 시의 전달인자, 지역 변수, 되돌아갈 주소 등을 저장
* 독립적인 스택을 갖는 것은 독립적인 함수 호출이 가능하고 독립적인 실행 흐름을 추가할 수 있다는 것을 의미

#### 스레드가 PC 레지스터를 가지는 이유
* 스레드는 CPU를 할당받고, 반납하고를 반복
* 이전까지의 수행 내역을 기억하기 위해 독립적인 PC 사용

<br>

## 멀티 프로세싱과 멀티 스레딩
* 멀티 코어 환경은 `공유 자원(Cirical Section)`이 있을 시 동기화 매커니즘이 필요

### 👉 멀티 프로세싱
* 다수의 프로세서(CPU)가 여러 작업을 동시에 처리하는 것 (병렬 처리)
* Pipe나 Shared Memory가 있어야 데이터를 주고 받을 수 있음
* `많은 메모리 공간`을 차지
* `IPC라는 별도 매커니즘`을 사용
* 프로세스 간의 통신 비용/문맥 교환 `비용이 큼`
* 안전성: 하나의 프로세스가 죽더라도 다른 프로세스에는 영향을 끼치지 않고 정상적으로 수행

#### IPC (Inter Process Communication)
* 프로세스 간의 통신을 하는 것으로 Pipe, 공유 메모리, 소켓 등을 통해서 구현

### 👉 멀티 스레딩
* 하나의 프로세스에 여러 스레드로 자원을 공유하며 작업을 나누어 수행하는 것
* 스레드 간은 `데이터/힙 영역을 공유`하므로 Shared Memory가 없어도 데이터를 주고 받을 수 있음
* `적은 메모리 공간`을 차지
* 프로세스를 생성하여 자원을 할당하는 시스템 콜이 감소함으로서 `자원을 효율적으로 관리`
* 스레드 간의 통신 비용과 문맥 교환 `비용이 적음`
* 하나의 스레드의 비정상적인 활동은 전체 스레드에 영향을 끼칠 수 있음

<br>

## Thread Safe와 Thread
* 멀티 스레딩 프로그램에서 일반적인 변수나 객체, 함수에 여러 스레드가 동시에 접근해도 프로그램 실행의 문제가 없는 상태
* Thread Safe한 코드: `Critical Section`을 통해 스레드 내부에서 처리되는 연산들을 `직렬화(Serialize)` 하여 한 번에 한 스레드에서 연산이 수행되도록 해야됨

<br>

## 병렬성과 동시성의 차이
* 병렬성: `멀티 코어`에서의 멀티 스레드, 각 코어들의 스레드가 동시에 실행
* 동시성: `싱글 코어`에서의 멀티 스레드, 여러 개의 스레드가 번갈아가며 실행

<br>

## 문맥 교환(Context Switching)
* 여러 작업을 번갈아 실행하여 동시에 처리될 수 있도록 하는 것
* 프로세스 사이에서 CPU 제어권이 이동되는 것
* Context: CPU가 해당 프로세스를 실행하기 위한 해당 프로세스의 정보, 각 프로세스의 `PCB`에 저장
* 과정
  1. 실행 중이던 프로세스의`상태(문맥)를 PCB에 보관`<br>
  2. 새로운 프로세스의 `PCB에서 문맥(Context)을 복원`해 레지스터에 적재<br>
  3. 새로운 프로세스 실행

<br>

## 인터럽트
* 프로그램을 실행하는 도중에 예기치 않은 상황이 발생할 경우 `현재 실행 중인 작업을 즉시 중단`하고, `발생된 상황을 우선 처리`한 후 `실행 중이던 작업으로 복귀`하여 계속 처리하는 것
* 문맥 교환을 구현할 때 Timer Interrupt를 통해서 제어권을 커널이 가져올 수 있도록 활용

<br>

## 프로세스 동기화
* 다중 프로세스 환경에서 자원에 한 프로세스만이 접근 가능하도록 하는 것
* 데이터 일관성이 깨지거나 결과가 잘못될 가능성이 있어 필요함

### 👉 Critical Section(공유 자원, 임계 영역)
* 동일한 자원에 동시에 접근하는 경우가 발생하는 코드 영역
* 접근 순서에 따라 실행 결과가 달라지는 구역

### 👉 Race Condition
* 공유 자원에 여러 프로세스/스레드가 접근할 경우 `접근 순서에 따라 결과가 달라지는 현상`

### 👉 뮤텍스와 세마포어의 차이
* 둘 다 `상호 배제`를 달성하는 기법
  * 상호 배제: 둘 이상의 프로세스/스레드가 동시에 임계 영역에 진입하는 것을 방지하기 위해 사용하는 알고리즘
#### 뮤텍스
* `스레드 기반`으로 공유 자원의 활용을 제어하는 방법
* 바이너리 세마포어와 비슷한 방식으로 `동기화 대상이 1개`일 때 사용 -> 1개 스레드만 접근 가능
* 소유 가능: `락`을 소유한 프로세스/스레드만이 락을 반환할 수 있음
#### 세마포어
* `프로세스 기반`으로 공유 자원의 활용을 제어하는 방법
* `동기화 대상이 여러 개`일 때 사용 -> `세마포어 변수(Counter)`만큼의 프로세스/스레드 접근 가능
  * 1: 바이너리 세마포어
  * 2 이상: 카운팅 세마포어
  * wait(): 세마포어 변수 1감소 -> Critical Section -> signal(): 세마포어 변수 1증가 
* 소유할 수 없음: 세마포어를 소유하지 않은 프로세스/스레드가 세마포어 해제 가능
* `Deadlock`이 발생할 수 있음

<br>

## 교착 상태 (Deadlock)
### 👉 정의
* 둘 이상의 프로세스/스레드가 자원을 점유한 상태에서 서로 다른 프로세스/스레드가 점유하고 있는 자원을 요구하며 `무한정 기다리는` 현상

### 👉 발생 조건
-> 4가지 조건을 모두 만족해야 됨<br>
* 상호 배제: 하나의 프로세스/스레드가 자원에 접근할 수 있음
* 비선점: 다른 프로세스/스레드의 자원을 뺏을 수 없음
* 점유와 대기: 자원을 가진 상태에서 다른 자원을 기다림
* 순환 대기: 순환 형태로 자원을 대기

### 👉 해결 방법
- 모든 프로세스가 `lock을 잡는 순서를 동일`하게 코딩
-  `trylock`을 활용하여 lock을 선점한 프로세스/스레드가 없을 때만 락을 얻으려고 시도하는 방법
* 예방: 4가지 조건 중 1개 이상이 만족하지 않도록 함
  * 상호 배제 부정: 여러 프로세스가 공유 자원을 사용하도록 함
  * 점유와 대기 부정: 프로세스가 실행되기 전 필요한 모든 자원을 할당
  * 비선점 부정: 자원을 점유 중인 프로세스가 다른 자원을 요구할 때, 점유 중인 자원을 반납하고 대기
  * 순환 대기 부정: 자원에 고유한 번호를 할당하고, 번호 순서대로 자원을 요구하도록 함
* 회피: 교착상태가 발생하지 않도록 알고리즘 작성
  * `은행원 알고리즘`: 어떤 자원을 할당하기 전에 할당 후에도 안정 상태로 있을 수 있는지 검사 후 할당
* 회복: 교착 상태 발생 후, 해당 프로세스를 종료하거나 할당된 자원을 해제 또는 선점하여 해결
  * 선점할 경우, `기아 상태`가 발생하지 않도록 해야 함
* 무시: 그냥 무시

<br>

## 기아 상태 (Starvation)
### 👉 정의
* 여러 프로세스가 부족한 자원을 점유하기 위해 경쟁할 때, `특정 프로세스가 영원히 자원 할당이 되지 않는 경우`

### 👉 해결 방법
* 프로세스의 우선 순위 변경
* 요청을 순서대로 처리하는 요청 큐 사용

### 👉 식사하는 철학자 문제

```
5명의 철학자가 원형 식탁에서 식사를 한다. 젓가락은 다섯개 뿐이며, 철학자는 반드시 두 젓가락이 있어야 식사를 할 수 있다. 철학자는 반드시 자신의 왼쪽 또는 오른쪽에 있는 젓가락만 사용할 수 있으며, 식사를 마친 후에는 두 젓가락을 모두 내려놓는다. 
```

#### 문제
* 모든 사람이 왼쪽의 젓가락을 잡으면 `교착상태` 발생 -> 무한히 대기하다가 `기아상태` 발생

#### 해결 방법
* 최대 4명의 철학자만 테이블에 동시에 앉을 수 있도록 한다.
* 한 철학자가 젓가락 두 개를 한번에 집을 수 있을 때만 집는다.
* 비대칭 해결안을 사용. 홀수 번호의 철학자는 왼쪽을 먼저 집고 오른쪽을 집는다. 짝수 번호는 오른쪽을 먼저 집고 왼쪽을 집는다.

<br>

## 동기와 비동기의 차이
### 👉 동기 (Synchronous) 정의 및 장단점
* 요청에 대한 응답을 기다린 후 `응답이 오면 실행`하는 방식
  * 함수가 끝나는 시간과 다음 함수가 시작되는 시간이 같음
* 호출한 함수가 작업 완료를 신경씀
* 구성이 단순하나 멀티태스킹이 불가능
* 결과가 주어질 때까지 대기해야 함

### 👉 비동기 (Asynchronous) 정의 및 장단점
* 요청에 대한 `응답을 기다리지 않고 실행`하는 방식
* 호출된 함수가 작업 완료를 신경씀 (Callback)
* 동기 방식보다 단위 시간 당 많은 작업 처리 가능
* 멀티태스킹이 가능하나 요청량이 많아질 경우 부하 컨트롤과 데이터의 일관성 유지 등 추가적인 처리가 필요 (복잡도 증가)

<br>

## 블락킹과 논블락킹의 차이
### 👉 블락킹
* 주로 I/0 처리 함수가 끝날 때까지 `기다리고` 결과를 받으면 자신의 작업을 이어서 진행
* 요청한 작업을 마칠 때까지 계속 기다림
* Thread 관점으로 본다면, 요청한 작업을 마칠 때까지 계속 대기하며 return 값을 받을 때까지 한 Thread를 계속 사용/대기

### 👉 논블락킹
* 논블락킹은 I/0 처리 함수가 끝나지 않더라도 `기다리지 않고` 다른 작업을 처리하는 방식
* 논블락킹은 요청한 작업을 즉시 마칠 수 없다면 즉시 리턴함
* Thread 관점으로 본다면, 하나의 Thread가 여러 개의 IO를 처리 가능하다.

<br>

## 블락킹/논블락킹과 동기/비동기의 차이
### 👉 동기/비동기
* 호출되는 함수의 `작업 완료 여부를 누가 신경쓰느냐가` 관심사
* 비동기는 `콜백`으로 호출된 함수가 완료 여부를 신경쓰고 호출한 함수는 그냥 자기 일을 하다가 콜백을 받으면 됨

### 👉 블락킹/논블락킹
* IO, 멀티 스레드를 처리하는 방법과 관련
* 호출되는 함수가 `바로 return하느냐 마느냐가` 관심사이다.

<br>

## CPU 스케줄링 기법
* SRT(Shortest Remaining Time): `남은 시간이 가장 적은` 프로세스를 실행
* Round Robin: 시간 조각(Time Slice)라고 하는 단위로 공평하게 프로세스 실행
  * 할당된 시간 내에 끝나지 않으면 다음 프로세스에게 CPU를 양보하고 준비 상태 큐의 가장 뒤로 배치
* MLFQ(Multi Level Feedback Queue): 우선 순위 개수만큼 Queue가 있으며 최상위 단계의 Queue부터 실행 후 해당 큐의 할당량이 끝나면 하위 우선 순위 Queue를 실행하는 스케줄링 기법으로 처음 시작은 모든 프로세스가 가장 높은 우선 순위 Queue에 존재하나 할당된 Time Slice를 소진하면 우선 순위를 감소시켜서 우선 순위를 정해가고 일정 주기마다 모든 작업을 가장 높은 우선 순위 큐로 이동시켜서 Starvation 방지(Aging)

<br>

## 메모리 구성
* 코드: 프로그램의 코드 저장
* 데이터: 전역 변수, 정적 변수 저장
* 스택: 지역 변수, 매개 변수, 함수의 호출과 할당, 컴파일에 크기 결정
* 힙: 동적으로 할당 및 해제, 런 타임에 크기 결정

### 👉 힙과 스택의 차이
* 힙: 프로그램 코드에서 `동적으로 할당`하여 사용되는 메모리 영역
* 스택: `함수를 호출`할 때나 `지역변수`를 지정할 때 `자동`으로 할당되는 메모리 영역

### 👉 스택 영역의 장점과 단점
* 장점: 자동으로 처리되기 때문에 `낭비되는 공간이 없고` 사용하기가 편리
* 단점: 한계가 있어 한계를 초과하도록 삽입할 수 없고 `유연성이 부족`

### 👉 힙 영역의 장점과 단점
* 장점: 프로그램에 필요한 개체의 개수나 크기를 미리 알 수 없는 경우 사용하고 개체가 너무 커서 스택 할당자에 맞지 않는 경우 사용 가능
* 단점: `할당/해제 작업`으로 인한 속도 저하

<br>

## 가상 메모리와 가상 메모리 사용 시의 장점
* 물리 메모리 크기의 한계를 극복하기 위해 나온 기술로 메모리가 실제 메모리보다 많아 보이게 하는 기술
* 프로그램에 실제 메모리 주소가 아닌 `가상의 메모리 주소를 주는 방식`으로 프로그램 별로 사용 중인 메모리보다 큰 메모리를 사용하는 듯한 환상을 주는 기법
* `MMU(Memory Management Unit)`는 가상 메모리 주소를 물리 주소로 변환
* 실제 프로그램 전체를 적재하여 사용하지 않고 일부분만 적재하기 때문에 메모리 제약을 극복
* 메모리의 실제 주소를 사용하지 않으므로 보안 상의 장점이 존재

<br>

## 세그멘테이션
* 프로세스를 서로 다른 크기의 논리적 단위인 `세그먼트`로 나누어 메모리에 배치하는 것
* 메모리를 세그먼트로 나누고 `세그먼트 테이블`에 각 세그먼트의 `시작(base) 주소`와 `크기(limit)` 정보를 운용하여 가상 메모리를 관리하는 기법
* `외부 단편화` 발생: 작은 메모리가 중간 중간 존재하여 총 메모리는 충분하지만 실제로는 할당할 수 없는 상황

<br>

## 페이징
* 프로세스를 `일정 크기인 페이지`로 잘라서 가상 메모리에 적재하고 `페이지 테이블`을 이용하여 프레임으로 변환하여 가상 메모리를 관리하는 기법
* 페이지: `가상 메모리`를 최소 단위로 쪼개어 만든 `일정한` 크기의 블럭
* 프레임: `물리 메모리`에 페이지 크기와 같은 블럭으로 나눈 블럭
* CPU가 가상 주소 접근 시 MMU가 페이지 테이블의 `시작(base) 주소`를 접근해서 물리주소 가져 옴
* `내부 단편화` 발생: 페이지가 다 채워지지 않아 발생하는 공간 낭비

## [참고] 페이지 테이블, TLB (Translation Lookaside Buffer)
* MMU는 TLB라는 캐시를 저장하고 있다. 가상주소가 물리 주소로 변환되어야할 때, `TLB`에서 우선 검색된다.
* 해당 되는 주소가 있으면 (TLB hit) 물리주소가 리턴되고 메모리에 접근한다. 하지만, TLB에서 해당되는 주소가 없을 경우 (TLB miss) `page table`에서 맵핑이 존재하는지 찾는다. 존재할 경우에 (page table hit) 이 값은 다시 TLB에 쓰이고 그 주소를 이용해 물리 주소로 변환 후, 메모리에 접근한다.
* page table에서도 찾지 못할 경우에는 `disk`에서 찾고, 그 값을 다시 page table과 TLB에 쓰고 물리주소로 변환 후 메모리에 접근한다.
* 요악: 가상 주소로 물리 주소에 접근할 때 `TLB -> page table -> disk` 순으로 접근한다.

## 페이지 교체 알고리즘
* FIFO: 페이지 교체 시점에 들어온 페이지 `순서대로` 페이지를 교체하는 알고리즘
  * `Belady의 모순` 발생: 페이지 프레임의 개수를 늘리면 Page Fault 발생이 감소할 것 같으나, 실제로는 실패가 증가할 수도 있음
* LRU(Least-Recently-Used): 페이지 교체 시점에 `가장 오랫동안 사용되지 않은` 페이지를 선택하여 교체하는 알고리즘
* LFU(Least-Frequently-Used): 페이지 교체 시점에 `참조 횟수가 가장 적은 페이지`를 교체하는 알고리즘

## 캐시의 지역성
* 시간 지역성: 최근에 참조된 주소의 내용은 곧 다음에 다시 참조되는 특성(순환, 재귀)
* 공간 지역성: 대부분의 실제 프로그램이 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성(배열)

## 컴퓨터가 부팅되는 과정
* 처음에 부팅이 되면 `BIOS`가 실행 될 수 있도록 `메모리의 0번지에는 ROM`이 올라와있고, `CPU는 0번지를 읽어` 자동으로 ROM의 BIOS가 실행
* `BIOS는 하드디스크의 0번지 부터 한 섹터를 읽어와 거기에 있는 부트스트랩 코드를 실행`시킨다. 부트스트랩이 `부트로더`(bootcamp, grub)를 실행시키고 그 다음 커널이 로드

## 심볼릭 링크와 하드 링크의 차이
* 심볼릭 링크(소프트 링크): 원본 파일의 이름을 가리키는 링크, 원본 파일이 사라지면 역할 수행X
* 하드 링크: 원본 파일의 이름을 가리키는 링크, 사본을 생성, 원본파일이 사라져도 원본과 동일한 내용의 파일을 가질 수 있음을 의미

## 컴파일러와 인터프리터의 차이
  * 고급 언어로 작성된 프로그램 -> 기계어로 번역

|컴파일러|인터프리터|
|:------:|:------:|
|프로그램 `전체`를 한 번에 번역|프로그램을 `한 줄씩` 번역|
|목적 프로그램(기계어)으로 번역 -> 링킹 -> 실행 가능한 실행파일(어셈블리, 바이너리 파일) 생성|번역과 동시에 프로그램 실행|
|목적 프로그램 생성|목적 프로그램 생성X|
|번역 속도 느림|번역 속도 빠름|
|실행 속도 빠름|실행 속도 느림|
|C, Java|Python|

## CPU와 GPU의 차이
|CPU|GPU|
|:------:|:------:|
|컴퓨터의 자원을 관리하는 중앙처리장치|반복적이고 비슷한 대량의 연산을 수행|
|`직렬` 처리에 최적화된 몇 개의 코어|`병렬` 처리용으로 설계된 수 천 개의 소형인 효율적인 코어로 구성<br>CPU보다 빠름|